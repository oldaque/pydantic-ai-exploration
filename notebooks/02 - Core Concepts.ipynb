{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "306dd424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from dataclasses import dataclass\n",
    "import httpx\n",
    "from rich import print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06e81c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")  # I don't have credit, it's only to show how fallback model wotks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a40d5f-d291-4293-94e8-12b6685bbb21",
   "metadata": {},
   "source": [
    "# Core Concepts\n",
    "\n",
    "This notebook explores core concepts of Pydantic AI: Agents, Dependencies, and Tools."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf5d960-a48d-4981-80ce-4611870ff4b1",
   "metadata": {},
   "source": [
    "## Agent\n",
    "\n",
    "An Agent is the core abstraction in Pydantic AI. It coordinates model calls, manages context, and orchestrates tool execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa4fbe4-1c30-495f-a7ea-90c2ad2b2fbf",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32440df7-f8d2-4f4e-a24f-fc4e9affe14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent, ModelSettings\n",
    "from pydantic_ai.models.groq import GroqModel\n",
    "from pydantic_ai.models.fallback import FallbackModel\n",
    "from pydantic_ai.models.openai import OpenAIChatModel\n",
    "\n",
    "# Configure each model with provider-specific settings\n",
    "openai_model = OpenAIChatModel(\n",
    "    'gpt-5',\n",
    "    settings=ModelSettings(temperature=0.2, max_tokens=100)\n",
    ")\n",
    "groq_model = GroqModel(\n",
    "    'llama-3.3-70b-versatile',\n",
    "    settings=ModelSettings(temperature=1.2, max_tokens=100)\n",
    ")\n",
    "\n",
    "# Fallback model: tries OpenAI first, then Groq if it fails\n",
    "fallback_model = FallbackModel(openai_model, groq_model)\n",
    "agent = Agent(fallback_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60057758-5a93-4f2a-bcf5-513780f1886f",
   "metadata": {},
   "source": [
    "### Running the Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1f120-5573-42a5-bbce-68ef01690d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute agent with a prompt\n",
    "\n",
    "result = await agent.run('Escreva uma história sobre exploração espacial. Português PT-BR.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2cd448-9d90-42d6-b7e0-147697220885",
   "metadata": {},
   "source": [
    "### Inspecting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3d3b78-771e-4f79-8702-ff42f6495d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the agent's final output\n",
    "\n",
    "Markdown(result.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf65eab6-0541-4604-966d-fd5017db26c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect all messages: requests, responses, and model reasoning\n",
    "\n",
    "result.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ac08b2-f4b9-44f3-b335-097728b6b90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the model's reasoning process\n",
    "\n",
    "Markdown(result.all_messages()[-1].thinking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663162a7-07d3-4984-87dc-d2701f8f1172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract which model was used from the fallback chain\n",
    "\n",
    "provider_name = result.all_messages()[-1].provider_name\n",
    "model_name = result.all_messages()[-1].model_name\n",
    "\n",
    "print(f\"Provider: {provider_name}\")\n",
    "print(f\"Model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d2a382-8530-4321-8097-8aeb058cb712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract token usage metrics\n",
    "\n",
    "request_usage = result.all_messages()[-1].usage\n",
    "\n",
    "print(f\"Input tokens: {request_usage.input_tokens}\")\n",
    "print(f\"Output tokens: {request_usage.output_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8292c8-aee6-4d2e-ad16-aed66a736372",
   "metadata": {},
   "source": [
    "### Key Concepts\n",
    "\n",
    "- **FallbackModel**: Chains multiple models—if the first fails, it automatically tries the next\n",
    "- **ModelSettings**: Configure temperature, max_tokens, and other inference parameters per model\n",
    "- **RunContext**: Provides access to dependencies, messages, and request metadata during execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a69273e-64f3-49f5-979c-3d32539fe6fd",
   "metadata": {},
   "source": [
    "## Dependencies\n",
    "\n",
    "Dependencies enable secure injection of shared resources (HTTP clients, databases, API keys) into agent tools without exposing them to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0040490-f653-43f6-b18a-8a7dd32bad50",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba1e6e-4b60-42cc-9c17-c90c7d7a6f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pydantic_ai import RunContext\n",
    "\n",
    "# Define a dependency container\n",
    "@dataclass\n",
    "class MyDeps:\n",
    "    \"\"\"Shared resources injected into agent tools\"\"\"\n",
    "    api_key: str\n",
    "    http_client: httpx.AsyncClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2ce3bf-f7bf-4c84-9d26-d929d16f4d75",
   "metadata": {},
   "source": [
    "### Configure Agent with Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff1f8cb-84a7-4f9c-8ac2-8c8ebfed76c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent with dependency type hint\n",
    "\n",
    "agent_with_deps = Agent(\n",
    "    model='groq:openai/gpt-oss-20b',\n",
    "    deps_type=MyDeps,\n",
    "    system_prompt='You are a helpful assistant that can fetch user information.'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8966028b-f0b3-4e2d-9b56-fdd320e96b65",
   "metadata": {},
   "source": [
    "### Define Tool Using Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05aaac4-98b3-48ab-b5a4-54bd10c8c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@agent_with_deps.tool\n",
    "async def get_user_info(ctx: RunContext[MyDeps], user_id: int) -> str:\n",
    "    \"\"\"Fetch user information using injected HTTP client and API key\"\"\"\n",
    "    # Access dependencies through context—no need to pass them explicitly\n",
    "    client = ctx.deps.http_client\n",
    "    api_key = ctx.deps.api_key\n",
    "    \n",
    "    # In production, this would make a real API call\n",
    "    user_data = {\n",
    "        'id': user_id,\n",
    "        'name': f'User {user_id}',\n",
    "        'email': f'user{user_id}@example.com',\n",
    "        'authenticated': True\n",
    "    }\n",
    "    \n",
    "    return str(user_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b8e1ed-d48e-4ace-8839-11f6d9b96a73",
   "metadata": {},
   "source": [
    "### Running Agent with Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febea89d-e9f4-483d-a055-bc881b7cda10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate dependencies and pass to agent\n",
    "\n",
    "async with httpx.AsyncClient() as client:\n",
    "    deps = MyDeps(\n",
    "        api_key='sk-example-key',\n",
    "        http_client=client\n",
    "    )\n",
    "    \n",
    "    result = await agent_with_deps.run(\n",
    "        'Tell me about user 42.',\n",
    "        deps=deps\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007c0865-4653-43ac-a8ca-8b0eb2a18cdb",
   "metadata": {},
   "source": [
    "### Inspecting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cadc8a3-fd4a-46f6-be74-5a1fd60d6800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display agent output\n",
    "\n",
    "Markdown(result.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57737125-7c20-45d5-979c-68bf4cfa09c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the entire message flow including tool calls\n",
    "\n",
    "result.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a045573-09a8-4398-b8ef-b0e7ca99407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract token usage\n",
    "\n",
    "request_usage = result.all_messages()[-1].usage\n",
    "\n",
    "print(f\"Input tokens: {request_usage.input_tokens}\")\n",
    "print(f\"Output tokens: {request_usage.output_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d42200-306e-461b-a9d1-0a3e5b953ac7",
   "metadata": {},
   "source": [
    "### Key Concepts\n",
    "\n",
    "- **Dependency Injection**: Resources are passed to the agent, not hardcoded in tools\n",
    "- **Backend Safety**: Sensitive data (API keys, DB connections) never reach the LLM—only tool logic sees them\n",
    "- **Resource Reuse**: A single HTTP client or database connection is shared across all tool calls\n",
    "- **Type Safety**: `deps_type` provides IDE autocompletion and type hints for dependency access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4498a18",
   "metadata": {},
   "source": [
    "## Function Tools\n",
    "\n",
    "Tools enable agents to perform actions and access external systems. Pydantic AI supports two types: `@agent.tool` (with RunContext) and `@agent.tool_plain` (without context)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddd8ea3-0227-46f1-a1f4-0e19519f9963",
   "metadata": {},
   "source": [
    "### Overview\n",
    "\n",
    "This example implements 'Jogo do Bicho' (The Animal Game), a traditional Brazilian lottery game where:\n",
    "- The agent draws a random animal (1-25)\n",
    "- Accesses the player's name from dependencies\n",
    "- Determines if the guess matches the drawn animal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3d8f6e-69de-456d-ac6f-f51927eb9ed1",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "ec19bc8c-f16d-466f-9376-adee58bae582",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Agent for 'Jogo do Bicho' game\n",
    "\n",
    "animal_game = Agent(\n",
    "    model='groq:openai/gpt-oss-20b',\n",
    "    deps_type=str,  # Dependencies is just the player's name\n",
    "    system_prompt=(\n",
    "        'You are hosting Jogo do Bicho (The Animal Game). Draw a random animal from 1-25, '\n",
    "        'check if the player\\'s guess matches. If correct, celebrate their win. '\n",
    "        'If wrong, tell them which animal was drawn. Always use the player\\'s name in your response.'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d385b3-07d1-4243-8888-c2025df816d1",
   "metadata": {},
   "source": [
    "### Tool without Context\n",
    "\n",
    "`@agent.tool_plain` is a simple function that doesn't need RunContext or dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "90a87739-dd0f-48f3-a9ac-fca5585d1376",
   "metadata": {},
   "outputs": [],
   "source": [
    "@animal_game.tool_plain\n",
    "def draw_animal() -> str:\n",
    "    \"\"\"Draw a random animal from the Jogo do Bicho game (1-25).\"\"\"\n",
    "    animals = [\n",
    "        'Avestruz', 'Águia', 'Burro', 'Borboleta', 'Cachorro',\n",
    "        'Cabra', 'Carneiro', 'Camelo', 'Cobra', 'Coelho',\n",
    "        'Corvos', 'Cabalo', 'Elefante', 'Estribo', 'Escorpião',\n",
    "        'Espelho', 'Espingarda', 'Estátua', 'Estrela', 'Estrondo',\n",
    "        'Foca', 'Formiga', 'Fruta', 'Faisão', 'Fazenda'\n",
    "    ]\n",
    "    drawn_number = random.randint(1, 25)\n",
    "    drawn_animal = animals[drawn_number - 1]\n",
    "    return f\"{drawn_number} - {drawn_animal}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db94ed19-1886-4025-9b3e-e2b3e4fecdd0",
   "metadata": {},
   "source": [
    "### Tool with Context\n",
    "\n",
    "`@agent.tool` has access to RunContext, allowing it to use dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a7bfeb2d-3fcd-440d-a7bb-fb894aeca28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@animal_game.tool\n",
    "def get_player_name(ctx: RunContext[str]) -> str:\n",
    "    \"\"\"Get the player's name from dependencies.\"\"\"\n",
    "    # ctx.deps contains the player name (a simple string)\n",
    "    return ctx.deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261fa96d-79a1-4a58-bcd8-864f8665b685",
   "metadata": {},
   "source": [
    "### Running the Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b11e59e7-02a2-4ed6-b454-124e00963c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the game with player's name as dependency\n",
    "\n",
    "result = await animal_game.run(\n",
    "    'My guess is Cobra (Snake)',\n",
    "    deps='João'  # Player's name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbb5175-8a23-4500-86f9-86fc83e2a59c",
   "metadata": {},
   "source": [
    "### Inspecting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "59050a5e-b170-4973-947d-dc304492707b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sorry João, the drawn animal was Formiga."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display game result\n",
    "\n",
    "Markdown(result.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "8b3cc63e-cbd8-46ae-bd60-89407f19a6e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ModelRequest(parts=[SystemPromptPart(content=\"You are hosting Jogo do Bicho (The Animal Game). Draw a random animal from 1-25, check if the player's guess matches. If correct, celebrate their win. If wrong, tell them which animal was drawn. Always use the player's name in your response.\", timestamp=datetime.datetime(2025, 11, 4, 3, 30, 45, 299339, tzinfo=datetime.timezone.utc)), UserPromptPart(content='My guess is Cobra (Snake)', timestamp=datetime.datetime(2025, 11, 4, 3, 30, 45, 299379, tzinfo=datetime.timezone.utc))]),\n",
       " ModelResponse(parts=[ThinkingPart(content='We need to get player name, draw random animal, compare guess to drawn animal. If match, celebrate. If not, tell animal. The guess: \"Cobra (Snake)\". Need mapping of animal names to numbers? Not provided. We could just compare guess string to drawn animal string. But need to get drawn animal name. The draw_animal function probably returns an object with name? Not specified. Let\\'s assume it returns something like {animal: \"Cobra\"}. We\\'ll call it. Then compare to guess.\\n\\nWe also need player\\'s name: call get_player_name. Then produce response.\\n\\nWe\\'ll need two function calls.\\n\\nWe need to ask get_player_name first to personalize. Then draw_animal. Then respond.'), ToolCallPart(tool_name='get_player_name', args='{}', tool_call_id='fc_ab4678bc-3ccd-4be5-82ee-32670e59ac39')], usage=RequestUsage(input_tokens=212, output_tokens=167), model_name='openai/gpt-oss-20b', timestamp=datetime.datetime(2025, 11, 4, 3, 30, 45, tzinfo=TzInfo(0)), provider_name='groq', provider_details={'finish_reason': 'tool_calls'}, provider_response_id='chatcmpl-55dfce96-5250-434c-bbde-b4e049cbe169', finish_reason='tool_call'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='get_player_name', content='João', tool_call_id='fc_ab4678bc-3ccd-4be5-82ee-32670e59ac39', timestamp=datetime.datetime(2025, 11, 4, 3, 30, 45, 687752, tzinfo=datetime.timezone.utc))]),\n",
       " ModelResponse(parts=[ThinkingPart(content='We have a user guess \"Cobra (Snake)\". We need to draw a random animal from 1-25 using function draw_animal. Then compare guess. We need to respond with the player\\'s name (João). If correct, celebrate. If wrong, tell them which animal was drawn.\\n\\nWe need to interpret guess. The guess \"Cobra (Snake)\" maps to a number? In Jogo do Bicho, the animals are associated with numbers 1-25, but we need mapping. But we are not given mapping. We might need to have a mapping. But maybe the function returns a number, we then need to map number to animal? The instructions: \"Draw a random animal from 1-25\" but maybe the function returns the number. We need to map numbers to animals. We don\\'t have mapping. Maybe the function draw_animal returns the animal name directly. Let\\'s call the function.'), ToolCallPart(tool_name='draw_animal', args='{}', tool_call_id='fc_f7254d01-9c03-4bb8-8283-1116c6155a2b')], usage=RequestUsage(input_tokens=236, output_tokens=208), model_name='openai/gpt-oss-20b', timestamp=datetime.datetime(2025, 11, 4, 3, 30, 46, tzinfo=TzInfo(0)), provider_name='groq', provider_details={'finish_reason': 'tool_calls'}, provider_response_id='chatcmpl-52d39636-59fd-46d2-a255-ba8e7c39723f', finish_reason='tool_call'),\n",
       " ModelRequest(parts=[ToolReturnPart(tool_name='draw_animal', content='22 - Formiga', tool_call_id='fc_f7254d01-9c03-4bb8-8283-1116c6155a2b', timestamp=datetime.datetime(2025, 11, 4, 3, 30, 46, 78913, tzinfo=datetime.timezone.utc))]),\n",
       " ModelResponse(parts=[ThinkingPart(content='The user guessed \"Cobra (Snake)\". The system draws 22 - Formiga (ant). They guessed wrong. According to instructions, we must respond with the player\\'s name (João), and tell them the animal drawn. Must use their name in response. Also note \"If correct, celebrate win. If wrong, tell them which animal was drawn.\" So answer: \"Sorry João, the drawn animal was Formiga.\" Use their name.'), TextPart(content='Sorry João, the drawn animal was Formiga.')], usage=RequestUsage(input_tokens=263, output_tokens=111), model_name='openai/gpt-oss-20b', timestamp=datetime.datetime(2025, 11, 4, 3, 30, 46, tzinfo=TzInfo(0)), provider_name='groq', provider_details={'finish_reason': 'stop'}, provider_response_id='chatcmpl-7b8c1fb6-d4d0-4a4f-8fdf-3e9275a7ab8b', finish_reason='stop')]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View all tool calls and responses\n",
    "\n",
    "result.all_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "20dc10d6-5adb-49c4-90a6-afd1cecd2859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Input tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">263</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Input tokens: \u001b[1;36m263\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Output tokens: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">111</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Output tokens: \u001b[1;36m111\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract token usage\n",
    "\n",
    "request_usage = result.all_messages()[-1].usage\n",
    "\n",
    "print(f\"Input tokens: {request_usage.input_tokens}\")\n",
    "print(f\"Output tokens: {request_usage.output_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46998b6-d8f8-4922-b351-a6592b154850",
   "metadata": {},
   "source": [
    "### Key Concepts\n",
    "\n",
    "- **`@agent.tool_plain`**: Simple function without context—ideal for stateless operations\n",
    "- **`@agent.tool`**: Receives `RunContext[DepsType]`—access dependencies, model state, and request info\n",
    "- **Tool Discovery**: Pydantic AI automatically discovers all decorated tools and exposes them to the model\n",
    "- **Tool Results**: Tools can return strings, Pydantic models, or JSON-serializable objects\n",
    "- **Async Support**: Both decorators support async functions for I/O-heavy operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa9ca8",
   "metadata": {},
   "source": [
    "```mermaid\n",
    "sequenceDiagram\n",
    "    participant Agent\n",
    "    participant LLM\n",
    "\n",
    "    Agent->>LLM: Envia prompts (System + User: \"My guess is 4\")\n",
    "    LLM-->>Agent: Decide usar a ferramenta: Call tool roll_dice()\n",
    "    Agent->>Agent: Executa roll_dice() (rola o dado)\n",
    "    Agent->>LLM: Retorno da ferramenta: ToolReturn \"4\"\n",
    "    LLM-->>Agent: Decide usar outra ferramenta: Call tool get_player_name()\n",
    "    Agent->>Agent: Executa get_player_name() (obtém o nome)\n",
    "    Agent->>LLM: Retorno da ferramenta: ToolReturn \"Anne\"\n",
    "    LLM-->>Agent: Constrói resposta final: ModelResponse \"Congratulations Anne, ...\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a9b924",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
